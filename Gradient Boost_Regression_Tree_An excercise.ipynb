{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a code exercise for gradient boost using regression tree.\n",
    "For algorithm, refer to \n",
    "https://www.youtube.com/watch?v=3CC4N4z3GJc&t=753s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: The code block for creating a regression tree and predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function choose the best feature given current data set. \n",
    "n_seq=8\n",
    "def BestFeature(Dataset, unvisited_feature,discrete):\n",
    "    # want to return the best feature and the resulting data split\n",
    "    # but before this , you can already calculate the the mse of the current data\n",
    "    \n",
    "    threshold=[]\n",
    "    mse=[]\n",
    "    #print(unvisited_feature)\n",
    "    for feature in unvisited_feature:\n",
    "        if discrete[feature]=='yes': # this is discrete \n",
    "            # feature is name\n",
    "            # feature level is number?\n",
    "            # next, for each level in the feature_level, get\n",
    "            mse.append(SplitDataSet(Dataset,feature, 0.5)[0])\n",
    "            threshold.append(0.5)\n",
    "        else: # the feature is continuous \n",
    "            # we first generate a threshold sequence \n",
    "            thres_seq=[   min(Dataset[feature])+i*(max(Dataset[feature])-min(Dataset[feature]))/(n_seq-1) \n",
    "                      for i in range(1,n_seq-1)   ]\n",
    "            mse_seq= [ SplitDataSet(Dataset,feature, x)[0] for x in thres_seq]\n",
    "            mse.append(min(mse_seq))\n",
    "            threshold.append(thres_seq[mse_seq.index(min(mse_seq))])\n",
    "        \n",
    "    # we complete the loop with mse  series\n",
    "    # we now return the best feature and the corresponding threshold \n",
    "    # for discrete, the corresponding threshold is always -1 \n",
    "    best_feature=unvisited_feature[mse.index(min(mse))]\n",
    "    best_threshold=threshold[mse.index(min(mse))]\n",
    "    # we also return the splitted dat\n",
    "    return best_feature,best_threshold\n",
    "    # best_feature is a string. best_threshold is a value. \n",
    "\n",
    "# This function split the data into two parts given the feature and the threshold (value)\n",
    "def SplitDataSet(Dataset,feature, value):\n",
    "# we only consider the binary classification case\n",
    "# given the dataset, feature and value, this function returns splitted data and the resulting MSE!\n",
    "    Data_left=Dataset[Dataset[feature]<value]\n",
    "    Data_right=Dataset[Dataset[feature]>=value]\n",
    "# we want to calculate the mse of the data_left, data_right\n",
    "    Total_mse=mse_cal(Data_left[y],Data_left['pre_predict'])+mse_cal(Data_right[y],Data_right['pre_predict'])\n",
    "    return Total_mse,Data_left, Data_right \n",
    "\n",
    "import math\n",
    "from statistics import mean \n",
    "def mse_cal(y_data,pre_predict):\n",
    "    residual=y_data-pre_predict\n",
    "    return(sum([pow((i-mean(residual)),2) for i in residual]))\n",
    "\n",
    "\n",
    "def createTree(Dataset, layer,features,discrete):\n",
    "    # we first need to check whether the layer has already reached the max\n",
    "    if (layer==maxlayer  ):\n",
    "        # you have already reached the deepest. \n",
    "        Tree=mean(Dataset[y]-Dataset['pre_predict'])\n",
    "    else:\n",
    "        best_feature,best_threshold=BestFeature(Dataset, features,discrete)\n",
    "        Tree = {}  # means that you want to generate a new son tree\n",
    "        # the new son tree should contain the following features:\n",
    "        Tree['spInd'] = best_feature # the feature you use to split the data\n",
    "        featuresNext=features\n",
    "        featuresNext.remove(best_feature)  # this feature would no longer be used in the next trees\n",
    "        Tree['spVal'] = best_threshold # the threshold value \n",
    "        data_left, data_right = SplitDataSet(Dataset,best_feature, best_threshold)[1],SplitDataSet(Dataset,best_feature, best_threshold)[2]\n",
    "        Tree['left'] = createTree(data_left,layer+1,featuresNext,discrete)\n",
    "        Tree['right'] = createTree(data_right,layer+1,featuresNext,discrete)\n",
    "    return Tree\n",
    "\n",
    "# the following is for prediction.\n",
    "def predict(sample, tree):\n",
    "    if (sample[tree['spInd']]<tree['spVal']):\n",
    "        pred = predict(sample,tree['left']) if type(tree['left']).__name__=='dict' else tree['left']\n",
    "    else:\n",
    "        pred = predict(sample,tree['right']) if type(tree['right']).__name__=='dict' else  tree['right']\n",
    "    return (pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: The code block for Gradient Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boost function\n",
    "def GradientBoost (data , maxlayer, max_tree_number,discrete,learn_rate ):\n",
    "    n=len(data)\n",
    "    current_data = data.copy()\n",
    "    current_tree_series = []\n",
    "    current_tree_series.append(  mean(current_data[y]) )\n",
    "    current_predict = [ mean(current_data[y])   for i in range(0,n)]\n",
    "    current_data['pre_predict'] = current_predict\n",
    "    while (len(current_tree_series)<=max_tree_number):\n",
    "        # you a whole data set, whose y value is residual. use this to create a tree. : create_tree(current_data, maxlayer, data_features_original)\n",
    "# thorough this step you get a new tree\n",
    "        data_features = data_features_original.copy()\n",
    "        new_tree=createTree(current_data, 1, data_features,discrete) # a tree always start from first layer\n",
    "        print(new_tree)\n",
    "        current_tree_series.append ( new_tree )\n",
    "       \n",
    "       # produce new prediction \n",
    "        new_predict = [ predict ( current_data.loc[i],new_tree ) for  i in range(0,n) ]\n",
    "        # add it to current predict with a learning rate\n",
    "        current_predict =list(map(lambda x,y:x+y, current_predict , [j * learn_rate for j in new_predict] ))\n",
    "        current_data['pre_predict']=current_predict\n",
    "     \n",
    "        \n",
    "        # use the residual as the y for the next tree.\n",
    "        \n",
    "        #print(sum(list(map(lambda x: abs(x), current_data[y]-current_data['pre_predict']))))\n",
    "    return current_tree_series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is a try. we first input the data, and then see whether the XGBoost works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "data= pd.read_excel('C:/Users/shufe/Dropbox/ds new/pwchkt.xlsx')\n",
    "data.isnull().any(axis=1) # 判定每行会不会有空值的记录。（某条记录但凡在一个变量上有空值，就认为此记录\n",
    "data=data.dropna(how='any')\n",
    "data=data[['age','creditamount','guarantors','housing','foreigner','creditrating']]\n",
    "data.loc[(data.creditrating == 2),'creditrating']=0\n",
    "data_features_original = list(data.columns) \n",
    "y='creditamount'\n",
    "data_features_original.remove(y)\n",
    "# we also need to create a dictionary indicating whether the feature is discrete or not\n",
    "discrete={'age':'no','creditamount':'no','guarantors':'yes','housing':'yes','foreigner':'yes','creditrating':'yes'}\n",
    "data_features=data_features_original.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'age', 'spVal': 50.42857142857143, 'left': 494.37397026022325, 'right': 2163.677483870968}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -1338.3489090909088, 'right': -233.72576611694134}}\n",
      "2032473.1776832961\n",
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'age', 'spVal': 66.14285714285714, 'left': 453.52182529597053, 'right': 5116.489295698925}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -1003.7616818181815, 'right': -175.29432458770617}}\n",
      "2020686.5011843732\n",
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': 4140.768051110952, 'right': 324.22640302552765}, 'right': {'spInd': 'age', 'spVal': 51.0, 'left': -93.3242534135072, 'right': -669.0207181762499}}\n",
      "2014707.9654289244\n",
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'age', 'spVal': 42.57142857142857, 'left': 89.10975770430247, 'right': 1050.2370629327888}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -720.7675243017328, 'right': -90.87741727592598}}\n",
      "2007689.1015681538\n",
      "{'spInd': 'age', 'spVal': 27.0, 'left': {'spInd': 'housing', 'spVal': 0.5, 'left': -637.4053792660494, 'right': -106.80651748975939}, 'right': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 335.1001319974347, 'right': 8.82208199948231}}\n",
      "2003662.486846595\n",
      "{'spInd': 'age', 'spVal': 27.0, 'left': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 17.95520914594116, 'right': -391.2762679733351}, 'right': {'spInd': 'guarantors', 'spVal': 0.5, 'left': 42.82825427259594, 'right': 379.43225746694384}}\n",
      "2002832.616646789\n",
      "{'spInd': 'age', 'spVal': 67.0, 'left': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 131.15262795027198, 'right': -75.15430783174112}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -1052.1958757212506, 'right': 1163.0281481993331}}\n",
      "2000293.505599281\n",
      "{'spInd': 'age', 'spVal': 27.0, 'left': {'spInd': 'housing', 'spVal': 0.5, 'left': -424.01485554592665, 'right': -22.36585076902598}, 'right': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 195.90305001440493, 'right': 2.819197321835441}}\n",
      "1998467.4336981243\n",
      "{'spInd': 'age', 'spVal': 67.0, 'left': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 79.16841372037182, 'right': -47.879927566866996}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -789.851706121397, 'right': 859.4985710257555}}\n",
      "1996854.2249075514\n",
      "{'spInd': 'age', 'spVal': 27.0, 'left': {'spInd': 'guarantors', 'spVal': 0.5, 'left': -78.52917829584005, 'right': -586.6985898832273}, 'right': {'spInd': 'housing', 'spVal': 0.5, 'left': 194.34438707523478, 'right': 21.50138693164497}}\n",
      "1996858.3388231467\n",
      "{'spInd': 'age', 'spVal': 67.0, 'left': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 60.6821524626604, 'right': -36.30812664273519}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -597.7641263239591, 'right': 635.6476857000806}}\n",
      "1995949.2545911493\n",
      "{'spInd': 'age', 'spVal': 51.0, 'left': {'spInd': 'housing', 'spVal': 0.5, 'left': -158.18760118033768, 'right': 64.73075578641085}, 'right': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 773.0343337832846, 'right': -533.0127122249764}}\n",
      "1991610.4397654017\n",
      "{'spInd': 'age', 'spVal': 67.0, 'left': {'spInd': 'guarantors', 'spVal': 0.5, 'left': -15.189931839544732, 'right': 81.2315801910741}, 'right': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 2472.7121314581805, 'right': -139.28742875918093}}\n",
      "1991091.3967358156\n",
      "{'spInd': 'age', 'spVal': 27.0, 'left': {'spInd': 'guarantors', 'spVal': 0.5, 'left': -51.167494612708836, 'right': -450.6756978081972}, 'right': {'spInd': 'housing', 'spVal': 0.5, 'left': 173.17936285578295, 'right': 10.458511689922766}}\n",
      "1991347.0836324955\n",
      "{'spInd': 'age', 'spVal': 51.0, 'left': {'spInd': 'housing', 'spVal': 0.5, 'left': -124.57462520719805, 'right': 52.659741511547665}, 'right': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 515.51836670909, 'right': -399.2396599177659}}\n",
      "1989244.10776926\n"
     ]
    }
   ],
   "source": [
    "maxlayer = 3\n",
    "max_tree_number = 15\n",
    "xixixi = GradientBoost (data , maxlayer, max_tree_number ,discrete,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
