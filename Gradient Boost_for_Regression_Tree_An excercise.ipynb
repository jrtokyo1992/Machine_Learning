{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a code exercise for gradient boost using regression tree.\n",
    "For algorithm, refer to \n",
    "https://www.youtube.com/watch?v=3CC4N4z3GJc&t=753s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: The code block for creating a regression tree and predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function choose the best feature given current data set. \n",
    "n_seq=8\n",
    "def BestFeature(Dataset, unvisited_feature,discrete):\n",
    "    # want to return the best feature and the resulting data split\n",
    "    # but before this , you can already calculate the the mse of the current data\n",
    "    orginal_mse=mse_cal(Dataset[y])\n",
    "    threshold=[]\n",
    "    mse=[]\n",
    "    #print(unvisited_feature)\n",
    "    for feature in unvisited_feature:\n",
    "        if discrete[feature]=='yes': # this is discrete \n",
    "            # feature is name\n",
    "            # feature level is number?\n",
    "            # next, for each level in the feature_level, get\n",
    "            mse.append(SplitDataSet(Dataset,feature, 0.5)[0])\n",
    "            threshold.append(0.5)\n",
    "        else: # the feature is continuous \n",
    "            # we first generate a threshold sequence \n",
    "            thres_seq=[   min(Dataset[feature])+i*(max(Dataset[feature])-min(Dataset[feature]))/(n_seq-1) \n",
    "                      for i in range(1,n_seq-1)   ]\n",
    "            mse_seq= [ SplitDataSet(Dataset,feature, x)[0] for x in thres_seq]\n",
    "            mse.append(min(mse_seq))\n",
    "            threshold.append(thres_seq[mse_seq.index(min(mse_seq))])\n",
    "        \n",
    "    # we complete the loop with mse  series\n",
    "    # we now return the best feature and the corresponding threshold \n",
    "    # for discrete, the corresponding threshold is always -1 \n",
    "    best_feature=unvisited_feature[mse.index(min(mse))]\n",
    "    best_threshold=threshold[mse.index(min(mse))]\n",
    "    # we also return the splitted dat\n",
    "    return best_feature,best_threshold\n",
    "    # best_feature is a string. best_threshold is a value. \n",
    "\n",
    "# This function split the data into two parts given the feature and the threshold (value)\n",
    "def SplitDataSet(Dataset,feature, value):\n",
    "# we only consider the binary classification case\n",
    "# given the dataset, feature and value, this function returns splitted data and the resulting MSE!\n",
    "    Data_left=Dataset[Dataset[feature]<value]\n",
    "    Data_right=Dataset[Dataset[feature]>=value]\n",
    "# we want to calculate the mse of the data_left, data_right\n",
    "    Total_mse=mse_cal(Data_left[y])+mse_cal(Data_right[y])\n",
    "    return Total_mse,Data_left, Data_right \n",
    "\n",
    "import math\n",
    "from statistics import mean \n",
    "def mse_cal(y_data):\n",
    "    return(sum([pow((i-mean(y_data)),2) for i in y_data]))\n",
    "\n",
    "\n",
    "def createTree(Dataset, layer,features,discrete):\n",
    "    # we first need to check whether the layer has already reached the max\n",
    "    if (layer==maxlayer  ):\n",
    "        # you have already reached the deepest. all you have to do is to return the average y\n",
    "        Tree=mean(Dataset[y])\n",
    "    else:\n",
    "        best_feature,best_threshold=BestFeature(Dataset, features,discrete)\n",
    "        Tree = {}  # means that you want to generate a new son tree\n",
    "        # the new son tree should contain the following features:\n",
    "        Tree['spInd'] = best_feature # the feature you use to split the data\n",
    "        featuresNext=features\n",
    "        featuresNext.remove(best_feature)  # this feature would no longer be used in the next trees\n",
    "        Tree['spVal'] = best_threshold # the threshold value \n",
    "        data_left, data_right = SplitDataSet(Dataset,best_feature, best_threshold)[1],SplitDataSet(Dataset,best_feature, best_threshold)[2]\n",
    "        Tree['left'] = createTree(data_left,layer+1,featuresNext,discrete)\n",
    "        Tree['right'] = createTree(data_right,layer+1,featuresNext,discrete)\n",
    "    return Tree\n",
    "\n",
    "# the following is for prediction.\n",
    "def predict(sample, tree):\n",
    "    if (sample[tree['spInd']]<tree['spVal']):\n",
    "        pred = predict(sample,tree['left']) if type(tree['left']).__name__=='dict' else tree['left']\n",
    "    else:\n",
    "        pred = predict(sample,tree['right']) if type(tree['right']).__name__=='dict' else  tree['right']\n",
    "    return (pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: The code block for XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGboost function\n",
    "def GradientBoost (data , maxlayer, max_tree_number,discrete,learn_rate ):\n",
    "    n=len(data)\n",
    "    current_data = data.copy()\n",
    "    current_predict = [0]*n\n",
    "    current_tree_series = []\n",
    "    while (len(current_tree_series)<=max_tree_number):\n",
    "        # you a whole data set, whose y value is residual. use this to create a tree. : create_tree(current_data, maxlayer, data_features_original)\n",
    "# thorough this step you get a new tree\n",
    "        data_features = data_features_original.copy()\n",
    "        #print(len(current_data))\n",
    "        #print(discrete)\n",
    "        new_tree=createTree(current_data, 1, data_features,discrete) # a tree always start from first layer\n",
    "        \n",
    "        print(new_tree)\n",
    "       # add it to tree_series with a learning rate learning rate\n",
    "       # produce new prediction and get the new residual\n",
    "        new_predict = [ predict ( current_data.loc[i],new_tree ) for  i in range(0,n) ]\n",
    "        #print(new_predict)\n",
    "        current_predict =list(map(lambda x,y:x+y, current_predict , [j * learn_rate for j in new_predict] ))\n",
    "        current_tree_series.append ( new_tree )\n",
    "       # print(len(current_predict))\n",
    "        residual = data[ y ] - current_predict\n",
    "        # use the residual as the y for the next tree.\n",
    "        current_data[ y ] = residual\n",
    "        print(sum(list(map(lambda x: abs(x), residual))))\n",
    "    return current_tree_series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is a try. we first input the data, and then see whether the XGBoost works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "data= pd.read_excel('C:/Users/shufe/Dropbox/ds new/pwchkt.xlsx')\n",
    "data.isnull().any(axis=1) # 判定每行会不会有空值的记录。（某条记录但凡在一个变量上有空值，就认为此记录\n",
    "data=data.dropna(how='any')\n",
    "data=data[['age','creditamount','guarantors','housing','foreigner','creditrating']]\n",
    "data.loc[(data.creditrating == 2),'creditrating']=0\n",
    "data_features_original = list(data.columns) \n",
    "y='creditamount'\n",
    "data_features_original.remove(y)\n",
    "# we also need to create a dictionary indicating whether the feature is discrete or not\n",
    "discrete={'age':'no','creditamount':'no','guarantors':'yes','housing':'yes','foreigner':'yes','creditrating':'yes'}\n",
    "data_features=data_features_original.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'age', 'spVal': 50.42857142857143, 'left': 3765.631970260223, 'right': 5434.935483870968}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': 1932.909090909091, 'right': 3037.5322338830583}}\n",
      "2783988.18642083\n",
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'age', 'spVal': 66.14285714285714, 'left': 3299.266063864451, 'right': 8113.426344086022}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': 1642.9727272727273, 'right': 2581.9023988005997}}\n",
      "2411874.586160041\n",
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': 6589.265294881298, 'right': 2794.7023439880904}, 'right': {'spInd': 'age', 'spVal': 27.0, 'left': 1796.9733698592797, 'right': 2251.871548737446}}\n",
      "2161460.3580885925\n",
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'age', 'spVal': 42.57142857142857, 'left': 2204.2701377501603, 'right': 3275.4296448326913}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': 1073.2201188355066, 'right': 1871.056137298993}}\n",
      "2011835.0381973279\n",
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'age', 'spVal': 66.14285714285714, 'left': 2016.0280882324914, 'right': 5985.892594150001}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': 912.2371010101806, 'right': 1590.3977167041442}}\n",
      "1933672.4407380952\n",
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': 4927.662285236112, 'right': 1704.390769758211}, 'right': {'spInd': 'age', 'spVal': 51.0, 'left': 1394.1251128962306, 'right': 801.1575170595075}}\n",
      "1888348.7854046982\n",
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'age', 'spVal': 50.42857142857143, 'left': 1365.0136774326186, 'right': 2528.712587470785}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': 571.6733834318254, 'right': 1153.387374947807}}\n",
      "1869757.436203414\n",
      "{'spInd': 'age', 'spVal': 27.0, 'left': {'spInd': 'housing', 'spVal': 0.5, 'left': 442.72763635004407, 'right': 974.7130237520169}, 'right': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 1392.185082757085, 'right': 1040.3967187037572}}\n",
      "1864156.8689028288\n",
      "{'spInd': 'age', 'spVal': 27.0, 'left': {'spInd': 'housing', 'spVal': 0.5, 'left': 376.3184908975376, 'right': 828.5060701892143}, 'right': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 1183.3573203435224, 'right': 884.3372108981935}}\n",
      "1866904.1336159525\n",
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'age', 'spVal': 66.14285714285714, 'left': 898.970804668885, 'right': 4066.7118409780614}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': 210.0256945813606, 'right': 706.9767256877371}}\n",
      "1873866.182534726\n",
      "{'spInd': 'age', 'spVal': 27.0, 'left': {'spInd': 'housing', 'spVal': 0.5, 'left': 203.7529795194885, 'right': 589.6679722710337}, 'right': {'spInd': 'guarantors', 'spVal': 0.5, 'left': 676.8747212469359, 'right': 1018.0531483424508}}\n",
      "1883330.4001112962\n",
      "{'spInd': 'creditrating', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': 3348.258510467256, 'right': 661.5229946764111}, 'right': {'spInd': 'age', 'spVal': 51.0, 'left': 545.6196673418438, 'right': 12.513777832369131}}\n",
      "1892685.9593283548\n",
      "{'spInd': 'age', 'spVal': 67.0, 'left': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 565.843192504529, 'right': 405.3972398863699}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -502.5284415778351, 'right': 1502.7075593248176}}\n",
      "1903174.8453462352\n",
      "{'spInd': 'age', 'spVal': 27.0, 'left': {'spInd': 'housing', 'spVal': 0.5, 'left': 13.683227235491078, 'right': 342.7076138790608}, 'right': {'spInd': 'guarantors', 'spVal': 0.5, 'left': 426.14679791057137, 'right': 710.453981917223}}\n",
      "1913960.8656671382\n",
      "{'spInd': 'age', 'spVal': 67.0, 'left': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 424.28259390420374, 'right': 284.2096978940099}, 'right': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -491.0711950277455, 'right': 1213.3794057395091}}\n",
      "1923571.946939822\n",
      "{'spInd': 'age', 'spVal': 27.0, 'left': {'spInd': 'guarantors', 'spVal': 0.5, 'left': 186.63714511281736, 'right': -314.8498493094213}, 'right': {'spInd': 'creditrating', 'spVal': 0.5, 'left': 430.1829733537335, 'right': 297.6259126197353}}\n",
      "1932527.7921383763\n"
     ]
    }
   ],
   "source": [
    "maxlayer = 3\n",
    "max_tree_number = 15\n",
    "xixixi = GradientBoost (data , maxlayer, max_tree_number ,discrete,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
