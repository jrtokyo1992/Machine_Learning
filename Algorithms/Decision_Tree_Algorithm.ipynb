{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Xt_je6E50nob"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'creditamount', 'guarantors', 'housing', 'foreigner']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "data= pd.read_excel('C:/Users/shufe/Dropbox/ds new/pwchkt.xlsx')\n",
    "data.isnull().any(axis=1) # 判定每行会不会有空值的记录。（某条记录但凡在一个变量上有空值，就认为此记录\n",
    "data=data.dropna(how='any')\n",
    "data=data[['age','creditamount','guarantors','housing','foreigner','creditrating']]\n",
    "data.loc[(data.creditrating == 2),'creditrating']=0\n",
    "data_features=list(data.columns) \n",
    "y='creditrating'\n",
    "data_features.remove(y)\n",
    "# we also need to create a dictionary indicating whether the feature is discrete or not\n",
    "discrete={'age':'no','creditamount':'no','guarantors':'yes','housing':'yes','foreigner':'yes','creditrating':'yes'}\n",
    "data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function:BestFeature\n",
    "Defind a function 'BestFeature', which gives the best feature for classfying given the current dataset and feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seq=8\n",
    "def BestFeature(Dataset, unvisited_feature):\n",
    "    # want to return the best feature and the resulting data split\n",
    "    # but before this , you can already calculate the the entropy of the current data\n",
    "    orginal_entropy=entropy_cal(Dataset[y])\n",
    "    threshold=[]\n",
    "    entropy_gain=[]\n",
    "    #print(unvisited_feature)\n",
    "    for feature in unvisited_feature:\n",
    "        if discrete[feature]=='yes': # this is discrete \n",
    "            # feature is name\n",
    "            # feature level is number?\n",
    "            # next, for each level in the feature_level, get\n",
    "            entropy_gain.append(SplitDataSet(Dataset,feature, 0.5)[0]-orginal_entropy)\n",
    "            threshold.append(0.5)\n",
    "        else: # the feature is continuous \n",
    "            # we first generate a threshold sequence \n",
    "            thres_seq=[   min(Dataset[feature])+i*(max(Dataset[feature])-min(Dataset[feature]))/(n_seq-1) \n",
    "                      for i in range(1,n_seq-1)   ]\n",
    "            entropy_seq= [ SplitDataSet(Dataset,feature, x)[0] for x in thres_seq]\n",
    "            entropy_gain.append(max(entropy_seq)-orginal_entropy)\n",
    "            threshold.append(thres_seq[entropy_seq.index(max(entropy_seq))])\n",
    "        \n",
    "    # we complete the loop with entropy_gain series\n",
    "    # we now return the best feature and the corresponding threshold \n",
    "    # for discrete, the corresponding threshold is always -1 \n",
    "    best_feature=unvisited_feature[entropy_gain.index(max(entropy_gain))]\n",
    "    best_threshold=threshold[entropy_gain.index(max(entropy_gain))]\n",
    "    # we also return the splitted dat\n",
    "    return best_feature,best_threshold\n",
    "    # best_feature is a string. best_threshold is a value. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function: SplitDataSet\n",
    "Split the current dataset by the given feature at given threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitDataSet(Dataset,feature, value):\n",
    "# we only consider the binary classification case\n",
    "# given the dataset, feature and value, this function returns splitted data and the resulting entropy!\n",
    "    Data_left=Dataset[Dataset[feature]<value]\n",
    "    Data_right=Dataset[Dataset[feature]>=value]\n",
    "# we want to calculate the entropy of the data_left, data_right\n",
    "    Total_entropy=entropy_cal(Data_left[y])*len(Data_left.index)/len(Dataset.index)+entropy_cal(Data_right[y])*len(Data_right.index)/len(Dataset.index)\n",
    "    return Total_entropy,Data_left, Data_right \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function: Entropy_Cal\n",
    "Calculate entropy of target variable for given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def entropy_cal(y_data):\n",
    "    p=sum(y_data==1)/len(y_data)\n",
    "    if (p==1 or p==0):\n",
    "        return(0)\n",
    "    else:\n",
    "        return(-p*math.log(p)-(1-p)*math.log(1-p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Program: createTree\n",
    "This is recursive function that creates a tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(Dataset, layer,features):\n",
    "    # we first need to check whether the layer has already reached the max\n",
    "    if (layer==maxlayer  ):\n",
    "        # you have already reached the deepest. all you have to do is to return the class that has the most sample\n",
    "        n_positive=sum(Dataset[y]==1)\n",
    "        n_negative=sum(Dataset[y]==0)\n",
    "        Tree=1*(n_positive>n_negative)+0*(n_positive<=n_negative)\n",
    "        \n",
    "    elif (len(set(Dataset[y]))==1):\n",
    "        Tree=Dataset[0] # since every one in the dataset has the same label.\n",
    "    else:\n",
    "        best_feature,best_threshold=BestFeature(Dataset, features)\n",
    "        Tree = {}  # means that you want to generate a new son tree\n",
    "        # the new son tree should contain the following features:\n",
    "        Tree['spInd'] = best_feature # the feature you use to split the data\n",
    "        featuresNext=features\n",
    "        featuresNext.remove(best_feature)  # this feature would no longer be used in the next trees\n",
    "        Tree['spVal'] = best_threshold # the threshold value \n",
    "        data_left, data_right = SplitDataSet(Dataset,best_feature, best_threshold)[1],SplitDataSet(Dataset,best_feature, best_threshold)[2]\n",
    "        Tree['left'] = createTree(data_left,layer+1,featuresNext)\n",
    "        Tree['right'] = createTree(data_right,layer+1,featuresNext)\n",
    "    return Tree\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spInd': 'guarantors',\n",
       " 'spVal': 0.5,\n",
       " 'left': {'spInd': 'age', 'spVal': 51.0, 'left': 1, 'right': 1},\n",
       " 'right': {'spInd': 'creditamount',\n",
       "  'spVal': 11450.142857142857,\n",
       "  'left': 1,\n",
       "  'right': 1}}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlayer=3\n",
    "createTree(data,1,data_features)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "decision-tree.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
