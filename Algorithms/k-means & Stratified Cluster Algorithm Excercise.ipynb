{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# The first is the most basic k means\n",
    "def kmeans(data,p):\n",
    "    # p is the number of group you want to divide.\n",
    "    # you first randomly take out the p samples as initial center\n",
    "    centers=data.sample(n=p)\n",
    "    # data是一个data frame,为了方便运算，我们先把它转成列表\n",
    "    data=data.values.tolist()\n",
    "    # 现在data成为一个列表，列表的每个元素也是列表，记录每个记录的所有信息\n",
    "    # 我想让每个记录成为数组，这样方便算一点，所以我做了下面的操作\n",
    "    data=[np.array(x) for x in data]\n",
    "    # 对centers 也做相同的事情, 转成一个以数组作为元素的列表\n",
    "    centers=centers.values.tolist()\n",
    "    centers=[np.array(x) for x in centers]\n",
    "    error=1000\n",
    "    iter_time=1\n",
    "    criteria=1\n",
    "    while error>criteria & iter_time<100:\n",
    "        clusters=[[] for i in range(1,p+1)]\n",
    "        class_result=[]\n",
    "        for sample in data: \n",
    "        # please turn each sample in array\n",
    "            temp=[sample for i in range(1,p+1)]  # 在这里,为了方便使用下面的map隐函数，我把sample扩增\n",
    "            z=list(map(lambda v1,v2: np.linalg.norm(v1 - v2),temp,centers)) # now z has all the distance from the sample to each of the center\n",
    "            clusters[z.index(min(z))].append(sample) \n",
    "            class_result.append(z.index(min(z)))\n",
    "        # 看sample跟哪个center 最近，我就把这个sample扔到哪个center管辖的cluster上。\n",
    "        # 循环结束\n",
    "    # cluster[i] 表示第i个聚类，里面都是数据组成的列表。也就是说，cluster[i]自己本身也是一个列表\n",
    "    #现在对每个数据都进行了这样的操作，cluster的归集完毕，现在可以开始的计算每个cluster里面的新center\\\n",
    "    #对clusters【i】而言，里面的元素全是array. 所以可以用reduce(sum,cluster[i])/len(cluster[i])来得到向量的均值\n",
    "    # 不过好像只用sum(cluster[i])/len(cluster[i]) 也可以\n",
    "    # reduce真的非常有用！加lambda 的reduce也非常有用\n",
    "        centers_new=[sum(x)/len(x) for x in clusters] # 这句话的意思是，从clusters 的每个聚类，计算里面的向量均值成为新的\n",
    "    # 现在开始计算centers_new 与 centers 之间的距离 centers_new 与centers 都是列表，列表的元素都是array\n",
    "        error=sum(list(map(lambda v1,v2: np.linalg.norm(v1-v2),centers_new,centers)))\n",
    "        #print(error)\n",
    "        centers=centers_new\n",
    "        iter_time=iter_time+1\n",
    "    \n",
    "    # now you have the cluster result\n",
    "    return class_result\n",
    "    # finally return \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we next write the code for the stratified cluster\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "def current_classify(clusters,clusters_index):\n",
    "    # in clusters, the element is cluster. each cluster itself is a list of all the sample. the sample is also LIST (not array)\n",
    "    # clusters_index store the id of each sample\n",
    "    e=[[x,y] for x in range(0,len(clusters)) for y in range(x+1,len(clusters))]\n",
    "    f=[cluster_dist(clusters[x],clusters[y]) for x in range(0,len(clusters)) for y in range(x+1,len(clusters))]\n",
    "    g=e[f.index(min(f))] # return the index of the two clusters that has the smallest distance\n",
    "    print(g)\n",
    "    # we first to combine the two clusters into one big one. \n",
    "    temp=clusters[g[0]]+clusters[g[1]]\n",
    "    temp_index=clusters_index[g[0]]+clusters_index[g[1]]\n",
    "    \n",
    "    \n",
    "    # we then drop the two clusters from the originl\n",
    "    clusters = [clusters[i] for i in range(0,len(clusters)) if i not in (g[0], g[1])]\n",
    "    clusters_index = [clusters_index[i] for i in range(0,len(clusters_index)) if i not in (g[0], g[1])]\n",
    "    clusters.append(temp)  # add the combined one to the clusters. Now the clusters is \n",
    "    clusters_index.append(temp_index)  # add the combined one to the clusters. Now the clusters is \n",
    "   \n",
    "    return clusters, clusters_index\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_dist(x,y):\n",
    "    a=[np.linalg.norm(np.array(v1)-np.array(v2)) for v1 in x for v2 in y]\n",
    "    return(sum(a)/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "data= pd.read_excel('C:/Users/shufe/Dropbox/ds new/pwchkt.xlsx')\n",
    "data.isnull().any(axis=1) # 判定每行会不会有空值的记录。（某条记录但凡在一个变量上有空值，就认为此记录\n",
    "data=data.dropna(how='any')\n",
    "data=data[['duration','creditamount','age']]\n",
    "# now we intialize the cluster and clusters\n",
    "clusters_index=list(range(0,1000))\n",
    "clusters_index=[[x] for x in clusters_index]\n",
    "data=data.values.tolist()\n",
    "data=[[x] for x in data]\n",
    "    # 现在data成为一个列表，列表的每个元素也是列表，记录每个记录的所有信息\n",
    "clusters=data\n",
    "p=10\n",
    "n=100\n",
    "while n>=p:\n",
    "    clusters, clusters_index=current_classify(clusters,clusters_index)\n",
    "    n=len(clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
