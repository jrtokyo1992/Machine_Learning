{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Reference:https://zhuanlan.zhihu.com/p/27126737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train a base model, get its measurement of performance, \n",
    "# and update the weights of eachdata sample.\n",
    "import numpy as np\n",
    "import math\n",
    "# input: \n",
    "# data: dataset. weight: the weight on each sample.\n",
    "def classify(data,weight):\n",
    "    y = data[:,1]\n",
    "    x = data[:,0]   \n",
    "    error = 10000000\n",
    "\n",
    "    for i in np.arange(0,len(x)): \n",
    "        y_predict=np.array([1 if k<x[i] else -1 for k in x])\n",
    "        # now we compare y_predict and y. we want to find out the samples that are mistakenly classified.\n",
    "        err=np.sum(weight[np.where(y_predict!=y) ]) # the error \n",
    "        if (err<error):\n",
    "            error=err\n",
    "            threshold_final=x[i]\n",
    "            mistake_final=np.where(y_predict!=y)\n",
    "            y_predict_final=y_predict\n",
    "\n",
    "    for i in np.arange(0,len(x)): \n",
    "        y_predict = np.array([1 if k>x[i] else -1 for k in x])\n",
    "        # The above is a very simple basic classifier\n",
    "        # now we compare y_predict and y. we want to find out the samples that are mistakenly classified.\n",
    "        err = np.sum(weight[np.where(y_predict!=y) ]) # the error \n",
    "        if (err<error):\n",
    "            error=err\n",
    "            threshold_final = x[i]\n",
    "            mistake_final = np.where(y_predict!=y)\n",
    "            y_predict_final = y_predict\n",
    "    # Set the weight of the newly generated base classifier\n",
    "    alpha = 0.5*math.log((1-error)/error) \n",
    "    # set the new weight for each data sample\n",
    "    weight_new = np.array([weight[k]*math.exp(-alpha*y[k]*y_predict_final[k]) for k in np.arange(0,len(x)) ])\n",
    "    weight_new = weight_new/np.sum(weight_new)\n",
    "    # you want to return y_predict, weight_new , alpha\n",
    "    return y_predict_final, weight_new, alpha,error,threshold_final  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error for the current esambled model is 0.30000000000000004\n",
      "The error for the current esambled model is 0.21428571428571427\n",
      "The error for the current esambled model is 0.18181818181818185\n"
     ]
    }
   ],
   "source": [
    "# This is just for a test.\n",
    "# input the data\n",
    "weight = np.ones(10)*0.1\n",
    "np.shape(weight)\n",
    "y = np.array([1,1,1,-1,-1,-1,1,1,1,-1])\n",
    "x = np.arange(0,10)\n",
    "c = np.stack((x,y)) \n",
    "d = c.transpose() \n",
    "current_predict = np.zeros(10)\n",
    "s=1 \n",
    "while s <= 3: # We assume that we only iterate up to 3 basic classifier\n",
    "    y_predict_new,weight_new,alpha_new,wucha,threshold_final = classify(d,weight)\n",
    "    print('The error for the current esambled model is',wucha) \n",
    "    weight = weight_new\n",
    "    current_predict = current_predict + alpha_new * y_predict_new\n",
    "    s = s + 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
