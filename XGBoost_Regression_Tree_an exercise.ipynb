{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for the XGBoost. \n",
    "XGBoost can regarded as a general version of gradient boost. \n",
    "In XGboost, the current model wnats to maximize the loss function L(y_i, F_(t-1)+output)+ 0.5*regular_coef*output.\n",
    "the second term is regularization term.\n",
    "For details, please refer to \n",
    "https://www.youtube.com/watch?v=OtD8wVaFm6E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost (data , maxlayer, max_tree_number,discrete,learn_rate,regular ):\n",
    "    n=len(data)\n",
    "    current_data = data.copy()\n",
    "    current_tree_series = []\n",
    "    current_tree_series.append( sum(current_data[y])/(len(data)+regular) )\n",
    "    current_predict = [ sum(current_data[y])/(len(data)+regular)  for i in range(0,n)]\n",
    "    current_data['pre_predict'] = current_predict\n",
    "    while (len(current_tree_series)<=max_tree_number):\n",
    "        # you a whole data set, whose y value is residual. use this to create a tree. : create_tree(current_data, maxlayer, data_features_original)\n",
    "# thorough this step you get a new tree\n",
    "        data_features = data_features_original.copy()\n",
    "        new_tree=createTree(current_data, 1, data_features,discrete,regular) # a tree always start from first layer\n",
    "        print(new_tree)\n",
    "        current_tree_series.append ( new_tree )\n",
    "       \n",
    "       # produce new prediction \n",
    "        new_predict = [ predict ( current_data.loc[i],new_tree ) for  i in range(0,n) ]\n",
    "        # add it to current predict with a learning rate\n",
    "        current_predict =list(map(lambda x,y:x+y, current_predict , [j * learn_rate for j in new_predict] ))\n",
    "        current_data['pre_predict']=current_predict\n",
    "     \n",
    "        \n",
    "        # use the residual as the y for the next tree.\n",
    "        \n",
    "        #print(sum(list(map(lambda x: abs(x), current_data[y]-current_data['pre_predict']))))\n",
    "    return current_tree_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -1019.8217760641518, 'right': -101.5829169581571}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -5.2983907082699355, 'right': 79.56377684698228}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -767.6680402241146, 'right': -76.20211760059304}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -3.974085372335797, 'right': 59.67823631472943}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -577.8600083005699, 'right': -57.16278780620598}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -2.980783301231625, 'right': 44.76273036266444}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -434.98253372075874, 'right': -42.88049220500804}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -2.2357519420075924, 'right': 33.57508789223427}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -327.4319072513404, 'right': -32.16667140128822}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -1.6769373151436735, 'right': 25.183596215827393}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -246.47346864523965, 'right': -24.12973116287087}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -1.257795512141391, 'right': 18.889407539227566}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -185.53222639779037, 'right': -18.10084477590995}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -0.9434160335503903, 'right': 14.168338553603222}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -139.658873717018, 'right': -13.578293905973743}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -0.7076140785743247, 'right': 10.627216176717676}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -105.12783351226062, 'right': -10.185716063505296}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -0.5307496018608179, 'right': 7.971133894027778}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -79.13468786362476, 'right': -7.6407840664511575}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -0.3980914857491303, 'right': 5.978891790658123}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -59.56841888635484, 'right': -5.731711033974859}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -0.29859057919176096, 'right': 4.484574907363803}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -44.83996366720131, 'right': -4.299625678631604}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -0.22395940926562224, 'right': 3.3637357563779853}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -33.753159463772235, 'right': -3.2253511851458723}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -0.1679819140125259, 'right': 2.5230302698621805}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -25.407598057894287, 'right': -2.4194874263648587}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -0.1259957039886195, 'right': 1.892444057345754}}\n",
      "{'spInd': 'housing', 'spVal': 0.5, 'left': {'spInd': 'foreigner', 'spVal': 0.5, 'left': -19.125499636986287, 'right': -1.8149711675731985}, 'right': {'spInd': 'age', 'spVal': 35.714285714285715, 'left': -0.09450372986151521, 'right': 1.4194615708579033}}\n"
     ]
    }
   ],
   "source": [
    "maxlayer = 3\n",
    "max_tree_number = 15\n",
    "xixixi = XGBoost (data , maxlayer, max_tree_number ,discrete,0.25,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function choose the best feature given current data set. \n",
    "n_seq=8\n",
    "def BestFeature(Dataset, unvisited_feature,discrete,regular):\n",
    "    # want to return the best feature and the resulting data split\n",
    "    # but before this , you can already calculate the the loss of the current data\n",
    "    \n",
    "    threshold=[]\n",
    "    loss=[]\n",
    "    #print(unvisited_feature)\n",
    "    for feature in unvisited_feature:\n",
    "        if discrete[feature]=='yes': # this is discrete \n",
    "            # feature is name\n",
    "            # feature level is number?\n",
    "            # next, for each level in the feature_level, get\n",
    "            loss.append(SplitDataSet(Dataset,feature, 0.5,regular)[0])\n",
    "            threshold.append(0.5)\n",
    "        else: # the feature is continuous \n",
    "            # we first generate a threshold sequence \n",
    "            thres_seq=[   min(Dataset[feature])+i*(max(Dataset[feature])-min(Dataset[feature]))/(n_seq-1) \n",
    "                      for i in range(1,n_seq-1)   ]\n",
    "            loss_seq= [ SplitDataSet(Dataset,feature, x, regular )[0] for x in thres_seq]\n",
    "            loss.append(min(loss_seq))\n",
    "            threshold.append(thres_seq[loss_seq.index(min(loss_seq))])\n",
    "        \n",
    "    # we complete the loop with loss  series\n",
    "    # we now return the best feature and the corresponding threshold \n",
    "    # for discrete, the corresponding threshold is always -1 \n",
    "    best_feature=unvisited_feature[loss.index(min(loss))]\n",
    "    best_threshold=threshold[loss.index(min(loss))]\n",
    "    # we also return the splitted dat\n",
    "    return best_feature,best_threshold\n",
    "    # best_feature is a string. best_threshold is a value. \n",
    "\n",
    "# This function split the data into two parts given the feature and the threshold (value)\n",
    "def SplitDataSet(Dataset,feature, value,regular):\n",
    "# we only consider the binary classification case\n",
    "# given the dataset, feature and value, this function returns splitted data and the resulting loss!\n",
    "    Data_left=Dataset[Dataset[feature]<value]\n",
    "    Data_right=Dataset[Dataset[feature]>=value]\n",
    "# we want to calculate the loss of the data_left, data_right\n",
    "    Total_loss=loss_cal(Data_left[y],Data_left['pre_predict'],regular\n",
    "                      )+loss_cal(Data_right[y],Data_right['pre_predict'],regular)\n",
    "    return Total_loss,Data_left, Data_right \n",
    "\n",
    "import math\n",
    "from statistics import mean \n",
    "def loss_cal(y_data,pre_predict,regular):\n",
    "    residual=y_data-pre_predict\n",
    "    return(sum([pow(i,2)/(len(y_data)+regular) for i in residual]))\n",
    "\n",
    "\n",
    "def createTree(Dataset, layer,features,discrete,regular):\n",
    "    # we first need to check whether the layer has already reached the max\n",
    "    if (layer==maxlayer  ):\n",
    "        # you have already reached the deepest. \n",
    "        Tree=sum(Dataset[y]-Dataset['pre_predict'])/(len(Dataset)+regular)\n",
    "    else:\n",
    "        best_feature,best_threshold=BestFeature(Dataset, features,discrete,regular)\n",
    "        Tree = {}  # means that you want to generate a new son tree\n",
    "        # the new son tree should contain the following features:\n",
    "        Tree['spInd'] = best_feature # the feature you use to split the data\n",
    "        featuresNext=features\n",
    "        featuresNext.remove(best_feature)  # this feature would no longer be used in the next trees\n",
    "        Tree['spVal'] = best_threshold # the threshold value \n",
    "        data_left, data_right = SplitDataSet(Dataset,best_feature, best_threshold,regular)[1],SplitDataSet(\n",
    "            Dataset,best_feature, best_threshold,regular)[2]\n",
    "        Tree['left'] = createTree(data_left,layer+1,featuresNext,discrete,regular)\n",
    "        Tree['right'] = createTree(data_right,layer+1,featuresNext,discrete,regular)\n",
    "    return Tree\n",
    "\n",
    "# the following is for prediction.\n",
    "def predict(sample, tree):\n",
    "    if (sample[tree['spInd']]<tree['spVal']):\n",
    "        pred = predict(sample,tree['left']) if type(tree['left']).__name__=='dict' else tree['left']\n",
    "    else:\n",
    "        pred = predict(sample,tree['right']) if type(tree['right']).__name__=='dict' else  tree['right']\n",
    "    return (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "data= pd.read_excel('C:/Users/shufe/Dropbox/ds new/pwchkt.xlsx')\n",
    "data.isnull().any(axis=1) # 判定每行会不会有空值的记录。（某条记录但凡在一个变量上有空值，就认为此记录\n",
    "data=data.dropna(how='any')\n",
    "data=data[['age','creditamount','guarantors','housing','foreigner','creditrating']]\n",
    "data.loc[(data.creditrating == 2),'creditrating']=0\n",
    "data_features_original = list(data.columns) \n",
    "y='creditamount'\n",
    "data_features_original.remove(y)\n",
    "# we also need to create a dictionary indicating whether the feature is discrete or not\n",
    "discrete={'age':'no','creditamount':'no','guarantors':'yes','housing':'yes','foreigner':'yes','creditrating':'yes'}\n",
    "data_features=data_features_original.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
